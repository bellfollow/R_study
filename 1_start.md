# 데이터 과학 및 AI 기반 의료 분석 스터디 가이드

## 핵심 개념 및 이론 이해

### 1. 빅데이터 
- 빅데이터의 정의
    - 전통적인 데이터 처리 방식으로는 관리하거나 분석하기 어려운 대규모 데이터를 의미함
    - 단순히 데이터의 양이 많다는 것 뿐아닌, 처리 속도와 데이터 형태의 다양성까지 포함하는 개념
- 기존 데이터 처리 방식과의 차이점
    - 전통적인 데이터 처리는 정형화된 소규모 데이터를 대상으로 했지만. 빅데이터는 정형,반정형,비정형 데이터를 모두 포함하며 실시간 처리 능력을 요구함

### 2. 데이터 분석의 5단계
1. 분석 기획 : 분석의 목적과 범위를 명확히 정의하고 분석 방향을 설정하는 단계
2. 데이터 준비 : 분석에 필요한 데이터를 수집,정제,변환하는 단계
3. 데이터 분석 : 데이터에 적절한 분석 기법을 적용하여 인사이트를 도출하는 단계
4. 시스템 구현 : 분석 결과를 실제 업무에 활용할 수 있도록 시스템화하는 단계
5. 평가 및 전개 : 구현된 시스템의 성과를 평가하고 개선점을 찾아 확산시키는 단계

### 3. 통계 기본 개념
- 통계의 기본 : [ 기술 통계 vs. 추론 통계 ] 각각의 정의와 목적, 대표적인 예시를 통해 두 개념의 차이를 명확히 이해합니다. 
    - 기술 통계 : 현재 보유한 데이터의 특성을 요약하고 설명하는 통계방법, 데이터의 중심 경향성과 분산 정도를 파악하는데 사용됨
        - 중심 경향성: 
    - 추론 통계 : 표본 데이터를 바탕으로 전체 모집단의 특성을 추론하고 예측하는 통계방법

------


- 통계량: 표본평균, 표본분산, 표준편차, 표준오차, 표본비율 등 주요 통계량의 개념과 의미를 이해합니다. 특히 분산과 표준편차가 데이터의 퍼짐 정도를 어떻게 설명하는지 파악합니다.
    - 표본평균: 표본에서 관측된 값들의 산숭평균, 데이터의 중심위치를 나타냄
    - 표본분산 : 표본 데이터가 평균으로 부터 얼마나 퍼져있는지를 측정하는 지표
    - 표준편차 : 표본분산의 제곱근으로, 데이터의 퍼짐 정도를 평균과 같은 단위로 표현함
    - 표준오차 : 표본통계량의 표준편차로, 표집분포의 변동성을 나타냄
    - 표본비율 : 전ㄴ체 표본에서 특정 속성을 가진 개체의 비율

------

- 데이터 전처리: 데이터 정제, 변환, 표본추출 등 데이터 전처리 작업의 목적과 중요성을 이해합니다.
    - 데이터 분석의 품질을 높이기위한 필수 과정
    - 데이터 정제 : 오류나 결측값을 제거하거나 보정하는 작업
    - 데이터 변환 : 분석에 적합한 형태로 데이터를 변환하는 과정
    - 표본 추출 : 모집단에서 대표성을 갖는 표본을 선태가흔ㄴ 과정 

------

- 표본 추출 방법: 단순임의추출, 층화임의추출, 체계적추출, 집락추출 등 다양한 확률 표본 추출 방법의 특징을 파악합니다.
    - 단순임의추출 : 모집단의 모든 개체가 동일한 확률로 선택될 수 있는 방법
    - 층화임의추출 : 모집단을 동질적인 층으로 나눈 후 각 층에서 임의 추출하는 방법
    - 체계적추출 : 일정한 간격으로 표본을 선택하는 방법
    - 집략추출 : 모집단을 집락으로 나눈 후 선택된 집락 내의 모든 개체를 조사하는 방법
        - 집락 : 

------

- 확률변수와 확률분포: 확률변수와 확률분포의 개념, 그리고 정규분포와의 관계를 이해합니다.
    - 확률 변수 : 표본공간의 각 원소에 실수값을 대응시키는 함수
    - 확률 분포 : 확률변수가 취할 수 있는 값들과 그 확률들의 대응관계
    - 정규 분포 : 자연현상에서 가장 많이 나타나는 연속확률분포로, 평균을 중심으로 대칭적인 종 모양을 갖습니다.
    - 중심극한정리 : 표본의 크기가 충분히 클 때 표본평균의 분포가 정규분포에 근사한다는 정리로, 통계적 추론의 이론적 근거가 됨

------

- 자료의 종류 및 변수: 양적 자료(연속형, 이산형)와 질적 자료(순서형, 명목형), 그리고 이에 따른 변수의 종류(등간변수, 비율변수, 서열변수, 명목변수)를 구분하고 이해합니다.
    - 양적 자료 : 수치로 측정 가능한 자료로 연속형(키,몸무게)과 이산형(자녀 수, 불량품 개수)으로 구분됨
    - 질적 자료 : 범주나 속성을 나타내는 자료로 순서형(학점,만족도)과 명목형(성별,혈액형)으로 구분됨
    - 등간변수 : 순서와 간격이 의미있는 변수임
    - 비율변수 : 절대적 영점이 존재하는 변수임
    - 서열변수 : 순서만 의미있는 변수입니다.
    - 명목변수 : 분류만 가능한 변수임

------

- 왜도 및 첨도: 분포 그래프의 외형을 설명하는 왜도와 첨도의 의미를 파악합니다.
    - 왜도 : 분포의 비대칭 정도를 나타내는 지표로, 분포 그래프가 어느 쪽으로 치우쳐 있는지 보여줌
    - 첨도 : 분포의 표쪽한 정도를 나타내는 지표로, 정규 분포와 비교하여 얼마나 뾰족하거나 평평한지를 측정함

------

- 가설 검정: 귀무가설과 대립가설의 개념, 1종 오류와 2종 오류의 의미, 그리고 가설 검정의 과정을 이해합니다. 유의 수준(alpha)과 검정력(1-beta)의 관계를 파악합니다.
    - 귀무가설 : 검정하고자 하는 효과나 차이가 없다고 가정하는 가설입니다. *
    - 대립가설 : 귀무가설에 대립되는 가설로, 연구자가 입증하고자 하는 가설 
    - 1종 오류 : 참인 귀무가설을 잘못 기각하는 오류로, 유의수준 알파와 동일합니다. *
    - 2종 오류 : 거짓인 귀무가설을 잘못 채택하는 오유로, 베타로 표시됩니다. *
    - 유의 수준(알파) : 1종 오류를 범할 확률의 최대 허용치
    - 검정력(1-beta) : 거짓인 귀무가설을 올바르게 기각할 확률

------

- t-검정: t-검정의 목적과 활용, t-분포와의 관계를 이해합니다.
    - 소표본에서 모집단의 평균을 검정하거나 두 집단의 평균을 비교할 때 사용하는 검정방법임.
- z-분포: 표준정규분포(z-분포)의 개념과 특징을 이해합니다.
    - 표준화된 정규분포로, 대표본에서 평균 검정에 사용됨
- 교차분석 및 카이제곱 검정: 범주형 자료 간의 관계를 파악하는 교차분석과 그 통계적 유의성을 검정하는 카이제곱 검정의 원리를 이해합니다.
    - 교차분석 : 두 범주형 변수간의 연관성을 분석하는 방법
    - 카이제곱 검정 : 범주형 자료에서 관찰빈도와 기대빈도의 차이를 검정하는 방법

------

### 4. 상관 및 회귀 분석

- 상관 분석: 두 변수 간의 선형적 관계 강도를 파악하는 상관 분석의 목적과 상관계수의 의미를 이해합니다. 공분산과 상관계수의 차이점을 파악합니다.
    - 상관 계수 : 두 변수 간의 선형적 관계의 강도와 방향을 나타내는 지표로, -1과 1사이의 값을 가집니다.
    - 공분산 : 두 변수가 함께 변하는 정도를 나타내는 지표로, 상관계수와 달리 단위에 영향을 받음
- 다중공선성: 다중공선성 문제의 의미와 해결 방법을 이해합니다.
    - 다중공산성 : 독립변수들 간의 높은 상관관계로 인해 회귀 분석 결과가 불안정해지는 문제

------

- AI 및 머신러닝 모델:주성분 분석(PCA): 차원 축소의 개념과 주성분 분석의 목적, 그리고 차원 축소를 통해 얻을 수 있는 이점(이해 용이성, 연산 속도 개선, 차원의 저주 해결)을 이해합니다. 직교의 의미를 파악합니다.


------

## 3. 통계 기본 개념

### 회귀 분석
- **추세선**: 데이터의 전반적인 경향을 나타내는 직선 또는 곡선입니다
- **최소제곱법(OLS)**: 관측값과 예측값 간의 오차 제곱합을 최소화하는 방법으로 회귀계수를 추정하는 기법입니다[1]
- **잔차**: 실제 관측값과 모델이 예측한 값의 차이입니다
- **회귀계수**: 독립변수가 종속변수에 미치는 영향의 크기를 나타내는 계수입니다
- **표준오차**: 회귀계수 추정치의 표준편차로, 추정의 정밀도를 나타냅니다
- **비선형 회귀**: 독립변수와 종속변수 간의 관계가 비선형일 때 사용하는 회귀분석 방법입니다

### 로지스틱 회귀
- **시그모이드 함수**: 0과 1 사이의 값을 출력하는 S자 형태의 함수로, 이진 분류에서 확률을 계산하는 데 사용됩니다
- **오즈비(Odds Ratio)**: 특정 사건이 발생할 확률과 발생하지 않을 확률의 비율로, 로지스틱 회귀에서 효과의 크기를 해석하는 지표입니다

## 6. 시계열 분석

- 시간 순서를 가진 데이터의 패턴을 분석하여 미래를 예측하는 기법입니다:
    - **정상성**: 시계열 데이터의 통계적 성질이 시간에 따라 변하지 않는 특성으로, 시계열 분석의 기본 전제입니다
    - **차분**: 비정상 시계열을 정상 시계열로 변환하기 위해 연속된 관측값의 차이를 구하는 방법입니다
    - **변환**: 로그변환, 제곱근변환 등을 통해 시계열의 분산을 안정화시키는 기법입니다

## 7. 머신러닝 알고리즘

### K-최근접 이웃(K-NN)
- 새로운 데이터 포인트를 분류하거나 예측할 때 가장 가까운 K개의 이웃 데이터를 참고하는 알고리즘입니다. 
- K값 선택이 모델 성능에 큰 영향을 미치며, 계산 비용이 높다는 단점이 있습니다.

### 의사결정나무(Decision Tree)
- 데이터를 규칙 기반으로 분할하여 트리 구조를 만드는 알고리즘입니다:
    - **노드 종류**: 뿌리 노드(최상위), 중간 노드(분할 기준), 끝마디(최종 분류 결과)로 구성됩니다
    - **분할 규칙**: 데이터를 가장 효과적으로 나누는 기준을 설정합니다
    - **순수도/불순도**: 노드 내 데이터의 동질성 정도를 측정하는 지표입니다
    - **엔트로피**: 불순도를 측정하는 방법 중 하나로, 정보 이론에 기반합니다
    - **정보 획득**: 분할 전후의 엔트로피 감소량으로, 최적 분할 기준을 선택하는 데 사용됩니다

### 랜덤 포레스트(Random Forest)
- 여러 개의 의사결정나무를 결합하여 예측 성능을 향상시키는 앙상블 알고리즘입니다:
    - **배깅(Bagging)**: 복원 추출을 통해 여러 표본을 만들어 각각 모델을 학습시키는 기법입니다
    - **부스팅(Boosting)**: 이전 모델의 오류를 보완하는 방향으로 순차적으로 모델을 학습시키는 기법입니다

### 서포트 벡터 머신(SVM)
- 데이터를 분류하기 위해 최적의 결정 경계를 찾는 알고리즘입니다:
    - **결정 경계**: 서로 다른 클래스를 구분하는 경계선입니다
    - **마진(Margin)**: 결정 경계와 가장 가까운 데이터 포인트 사이의 거리입니다
    - **서포트 벡터**: 결정 경계와 가장 가까운 위치에 있는 데이터 포인트들입니다
    - **하드 마진 vs 소프트 마진**: 하드 마진은 모든 데이터를 완벽히 분류하려 하고, 소프트 마진은 일부 분류 오류를 허용합니다
    - **이상치(outlier) 처리**: 소프트 마진을 통해 이상치의 영향을 줄일 수 있습니다

### DBSCAN
- 밀도 기반 군집 분석 알고리즘으로, 임의의 모양의 군집을 찾을 수 있습니다:
    - **코어 포인트**: 지정된 반지름 내에 최소 개수 이상의 이웃을 가진 점입니다
    - **보더 포인트**: 코어 포인트의 이웃이지만 자신은 코어 포인트가 아닌 점입니다
    - **노이즈 포인트**: 어떤 군집에도 속하지 않는 점입니다
    - **최적 반지름 설정**: 군집의 품질을 결정하는 중요한 매개변수입니다
    - **최소 군집 개수**: 코어 포인트가 되기 위한 최소 이웃 수입니다

## 8. 차원 축소

### 주성분 분석(PCA)
- 고차원 데이터를 저차원으로 축소하면서 정보 손실을 최소화하는 기법입니다:
    - **차원 축소 개념**: 많은 변수를 적은 수의 주요 성분으로 요약하는 과정입니다
    - **차원의 저주 해결**: 고차원에서 발생하는 데이터 희소성 문제를 해결합니다
    - **직교의 의미**: 주성분들이 서로 독립적이며 상관관계가 없다는 의미입니다
    - **연산 속도 개선**: 변수 수를 줄여 계산 복잡도를 감소시킵니다

## 9. 앙상블 학습

- 여러 개의 머신러닝 모델을 결합하여 단일 모델보다 더 나은 예측 성능을 얻는 기법입니다. 
- 개별 모델의 약점을 보완하고 전체적인 예측 정확도를 향상시키는 것이 목적입니다.
